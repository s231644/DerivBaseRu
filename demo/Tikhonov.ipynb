{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Извлеваем все сложные слова из датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"classification_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma_c</th>\n",
       "      <th>morphemes</th>\n",
       "      <th>is_in_tikhonov</th>\n",
       "      <th>n_roots</th>\n",
       "      <th>pos_c</th>\n",
       "      <th>is_in_wiktionary</th>\n",
       "      <th>is_compound</th>\n",
       "      <th>is_derived</th>\n",
       "      <th>needs_analysis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>одуматься</td>\n",
       "      <td>о:PREF/дум:ROOT/а:SUFF/ть:SUFF/ся:POSTFIX</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>VERB</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>врать</td>\n",
       "      <td>вр:ROOT/а:SUFF/ть:SUFF</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>VERB</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>хлюстовой</td>\n",
       "      <td>хлюст:ROOT/ов:SUFF/ой:END</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>отклеить</td>\n",
       "      <td>от:PREF/кле:ROOT/и:SUFF/ть:SUFF</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>VERB</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>писание</td>\n",
       "      <td>пис:ROOT/а:SUFF/ни:SUFF/е:END</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lemma_c                                  morphemes  is_in_tikhonov  \\\n",
       "0  одуматься  о:PREF/дум:ROOT/а:SUFF/ть:SUFF/ся:POSTFIX               1   \n",
       "1      врать                     вр:ROOT/а:SUFF/ть:SUFF               1   \n",
       "2  хлюстовой                  хлюст:ROOT/ов:SUFF/ой:END               1   \n",
       "3   отклеить            от:PREF/кле:ROOT/и:SUFF/ть:SUFF               1   \n",
       "4    писание              пис:ROOT/а:SUFF/ни:SUFF/е:END               1   \n",
       "\n",
       "   n_roots pos_c  is_in_wiktionary  is_compound  is_derived  needs_analysis  \n",
       "0        1  VERB                 1            0         1.0             0.0  \n",
       "1        1  VERB                 1            0         1.0             0.0  \n",
       "2        1   NaN                 0            0         NaN             0.0  \n",
       "3        1  VERB                 1            0         1.0             0.0  \n",
       "4        1  NOUN                 1            0         1.0             0.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72034"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"classification_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma_c</th>\n",
       "      <th>morphemes</th>\n",
       "      <th>is_in_tikhonov</th>\n",
       "      <th>n_roots</th>\n",
       "      <th>pos_c</th>\n",
       "      <th>is_in_wiktionary</th>\n",
       "      <th>is_compound</th>\n",
       "      <th>is_derived</th>\n",
       "      <th>needs_analysis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>упасти</td>\n",
       "      <td>у:PREF/пас:ROOT/ти:SUFF</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>VERB</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>передняя</td>\n",
       "      <td>перед:ROOT/н:SUFF/яя:END</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>воскрыляться</td>\n",
       "      <td>вос:PREF/крыл:ROOT/я:SUFF/ть:SUFF/ся:POSTFIX</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>VERB</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>лядунка</td>\n",
       "      <td>лядун:ROOT/к:SUFF/а:END</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>бурить</td>\n",
       "      <td>бур:ROOT/и:SUFF/ть:SUFF</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>VERB</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        lemma_c                                     morphemes  is_in_tikhonov  \\\n",
       "0        упасти                       у:PREF/пас:ROOT/ти:SUFF               1   \n",
       "1      передняя                      перед:ROOT/н:SUFF/яя:END               1   \n",
       "2  воскрыляться  вос:PREF/крыл:ROOT/я:SUFF/ть:SUFF/ся:POSTFIX               1   \n",
       "3       лядунка                       лядун:ROOT/к:SUFF/а:END               1   \n",
       "4        бурить                       бур:ROOT/и:SUFF/ть:SUFF               1   \n",
       "\n",
       "   n_roots pos_c  is_in_wiktionary  is_compound  is_derived  needs_analysis  \n",
       "0        1  VERB                 1            0         1.0             0.0  \n",
       "1        1  NOUN                 1            0         0.0             0.0  \n",
       "2        1  VERB                 1            0         1.0             0.0  \n",
       "3        1  NOUN                 1            0         0.0             0.0  \n",
       "4        1  VERB                 1            0         1.0             0.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_compounds = train_df[train_df[\"n_roots\"] > 1]\n",
    "test_compounds = test_df[test_df[\"n_roots\"] > 1]\n",
    "\n",
    "train_compounds = train_compounds[[\"lemma_c\", \"pos_c\"]]\n",
    "test_compounds = test_compounds[[\"lemma_c\", \"pos_c\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14282, 4704)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_compounds), len(test_compounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma_c</th>\n",
       "      <th>pos_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>чертыхаться</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>милливольтметр</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>санитарно-ветеринарный</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>морфемный</td>\n",
       "      <td>ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>богомильский</td>\n",
       "      <td>ADJ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   lemma_c pos_c\n",
       "11             чертыхаться  VERB\n",
       "15          милливольтметр  NOUN\n",
       "23  санитарно-ветеринарный   NaN\n",
       "32               морфемный   ADJ\n",
       "33            богомильский   ADJ"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_compounds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma_c</th>\n",
       "      <th>pos_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>родословие</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>кругорама</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>горько-сладкий</td>\n",
       "      <td>ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>фрезерно-центровальный</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>некредитоспособный</td>\n",
       "      <td>ADJ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   lemma_c pos_c\n",
       "8               родословие  NOUN\n",
       "10               кругорама   NaN\n",
       "13          горько-сладкий   ADJ\n",
       "14  фрезерно-центровальный   NaN\n",
       "16      некредитоспособный   ADJ"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_compounds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Запустить DerivBase.Ru (желательно применить multiprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "import warnings\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(\"../\") # go to parent dir\n",
    "from src.Derivation import Derivation\n",
    "derivator = Derivation(use_guesser=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pos_tag(word):\n",
    "    try:\n",
    "        tag = derivator.tag_guesser.morph.parse(word)[0].tag.POS\n",
    "        if tag == \"INFN\":\n",
    "            return \"VERB\"\n",
    "        if tag == \"NUMR\":\n",
    "            return \"NUM\"\n",
    "        if tag == \"ADJF\":\n",
    "            return \"ADJ\"\n",
    "        if tag == \"PRTF\":\n",
    "            return \"PART\"\n",
    "        if tag == \"GRND\":\n",
    "            return \"TRG\"\n",
    "        return tag\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1b83b7ecec34e2c99118f3dfe2dee8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14282 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1497bede23bb4d9186372597adab00e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4704 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "words_by_pos = defaultdict(set)\n",
    "derivator.pos_all.append('part')\n",
    "pos_all = derivator.pos_all\n",
    "\n",
    "for dataset in (train_compounds, test_compounds):\n",
    "    for line in tqdm(dataset.values):\n",
    "        lemma, pos = line\n",
    "        if pos is None:\n",
    "            pos = get_pos_tag(lemma)\n",
    "        try:\n",
    "            pos = pos.strip().lower()\n",
    "        except:\n",
    "            pos = None\n",
    "        if pos is None:\n",
    "            if any([lemma.endswith('ый'), lemma.endswith('ий'), lemma.endswith('ой')]):\n",
    "                words_by_pos[\"adj\"].add(lemma)\n",
    "            elif any([lemma.endswith('ть'), lemma.endswith('ти'), lemma.endswith('ться'), lemma.endswith('тись')]):\n",
    "                words_by_pos[\"verb\"].add(lemma)\n",
    "            else:\n",
    "                words_by_pos[\"noun\"].add(lemma)\n",
    "        else:\n",
    "            words_by_pos[pos].add(lemma)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_connections(word_b, pos_b, pos_a):\n",
    "    connections = []\n",
    "    derived = derivator.derive(word_b, pos_b=pos_b, pos_a=pos_a, is_extended=True, use_rare=True)\n",
    "    for rule_id, derived_words in derived.items():\n",
    "        exist_in_vocabulary = words_by_pos[pos_a] & derived_words\n",
    "        connections.extend([(word_b, pos_b, word_a, pos_a, rule_id) for word_a in exist_in_vocabulary])\n",
    "    return connections\n",
    "\n",
    "def find_all_word_connections(word_b, pos_b):\n",
    "    connections = []\n",
    "    for pos_a in pos_all:\n",
    "        connections.extend(find_connections(word_b, pos_b, pos_a))\n",
    "    return connections\n",
    "\n",
    "def find_all_pos_connections(pos_b):\n",
    "    connections = []\n",
    "    for word_b in tqdm(words_by_pos[pos_b], desc=pos_b):\n",
    "        # NOTE: убрать этот иф!\n",
    "        if len(connections) >= 10:\n",
    "            break\n",
    "        connections.extend(find_all_word_connections(word_b, pos_b))\n",
    "    return connections\n",
    "\n",
    "def find_all_connections():\n",
    "    connections = []\n",
    "    for pos_b in pos_all:\n",
    "        connections.extend(find_all_pos_connections(pos_b))\n",
    "    return connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('морфема', 'noun', 'морфемный', 'adj', 'rule619(noun + н1(ый) -> adj)')]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_all_word_connections('морфема', 'noun')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43fb1eb764024122b6ad36c72bbefc4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "noun:   0%|          | 0/9929 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3901d732ccea4a29a15462095bc5f1f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adj:   0%|          | 0/8369 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27080c1787904fa8ae17d0ed229e1354",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "verb:   0%|          | 0/565 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d41290ef92f4d9aa36aa5384cfae037",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adv:   0%|          | 0/106 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1132a0e315284f9089ac5cf62eb7fc1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "num:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da3bda6d91514eccb24e3c8ed32fa3d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "part: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_connections = find_all_connections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('голодранка',\n",
       "  'noun',\n",
       "  'голодранка',\n",
       "  'noun',\n",
       "  'rule415(noun + к(а)/очк(а) -> noun)'),\n",
       " ('сандружина',\n",
       "  'noun',\n",
       "  'сандружинница',\n",
       "  'noun',\n",
       "  'rule348(noun + ниц(а) -> noun)'),\n",
       " ('политотдел', 'noun', 'политотделец', 'noun', 'rule414(noun + ец -> noun)'),\n",
       " ('шубенка', 'noun', 'шубенка', 'noun', 'rule415(noun + к(а)/очк(а) -> noun)'),\n",
       " ('парапсихология',\n",
       "  'noun',\n",
       "  'парапсихологический',\n",
       "  'adj',\n",
       "  'rule630(noun + ск(ий) -> adj)'),\n",
       " ('гелиотроп', 'noun', 'гелиотропизм', 'noun', 'rule355(noun + изм -> noun)'),\n",
       " ('гелиотроп', 'noun', 'гелиотропин', 'noun', 'rule360(noun + ин -> noun)'),\n",
       " ('короткометражка',\n",
       "  'noun',\n",
       "  'короткометражка',\n",
       "  'noun',\n",
       "  'rule415(noun + к(а)/очк(а) -> noun)'),\n",
       " ('короткометражка',\n",
       "  'noun',\n",
       "  'короткометражный',\n",
       "  'adj',\n",
       "  'rule619(noun + н1(ый) -> adj)'),\n",
       " ('мелочевка',\n",
       "  'noun',\n",
       "  'мелочевка',\n",
       "  'noun',\n",
       "  'rule415(noun + к(а)/очк(а) -> noun)'),\n",
       " ('нейролептический',\n",
       "  'adj',\n",
       "  'нейролептик',\n",
       "  'noun',\n",
       "  'rule460(adj + 0m2 -> noun)'),\n",
       " ('бомбардирский', 'adj', 'бомбардир', 'noun', 'rule460(adj + 0m2 -> noun)'),\n",
       " ('бомбардирский',\n",
       "  'adj',\n",
       "  'бомбардировать',\n",
       "  'verb',\n",
       "  'rule807(adj + ова(ть) -> verb)'),\n",
       " ('силикальцитный',\n",
       "  'adj',\n",
       "  'силикальцит',\n",
       "  'noun',\n",
       "  'rule459(adj + 0m2 -> noun)'),\n",
       " ('силикальцитный',\n",
       "  'adj',\n",
       "  'силикальцит',\n",
       "  'noun',\n",
       "  'rule460(adj + 0m2 -> noun)'),\n",
       " ('камазовский',\n",
       "  'adj',\n",
       "  'камазовец',\n",
       "  'noun',\n",
       "  'rule287(adj + ец/евец/авец -> noun)'),\n",
       " ('мягкосердечный',\n",
       "  'adj',\n",
       "  'мягкосердечие',\n",
       "  'noun',\n",
       "  'rule320(adj + иj(е)/j(е)/ствиj(е) -> noun)'),\n",
       " ('строкорезный', 'adj', 'строкорез', 'noun', 'rule459(adj + 0m2 -> noun)'),\n",
       " ('строкорезный', 'adj', 'строкорез', 'noun', 'rule460(adj + 0m2 -> noun)'),\n",
       " ('пятиверстный',\n",
       "  'adj',\n",
       "  'пятиверстка',\n",
       "  'noun',\n",
       "  'rule293(adj + к(а)/ушк(а)/ашк(а)/анк(а)/инк(а)/овк(а)/лк(а)/ловк(а)/шк(а) -> noun)'),\n",
       " ('этимологизироваться',\n",
       "  'verb',\n",
       "  'деэтимологизироваться',\n",
       "  'verb',\n",
       "  'rule858(де + verb -> verb)'),\n",
       " ('умилостивлять',\n",
       "  'verb',\n",
       "  'умилостивляться',\n",
       "  'verb',\n",
       "  'rule930(verb + ся -> verb)'),\n",
       " ('бомбардироваться',\n",
       "  'verb',\n",
       "  'бомбардирование',\n",
       "  'noun',\n",
       "  'rule256(verb + ниj(е) -> noun)'),\n",
       " ('бомбардироваться',\n",
       "  'verb',\n",
       "  'бомбардировка',\n",
       "  'noun',\n",
       "  'rule262(verb + к(а)/овк(а)/ёжк(а) -> noun)'),\n",
       " ('происходить',\n",
       "  'verb',\n",
       "  'происхождение',\n",
       "  'noun',\n",
       "  'rule256(verb + ниj(е) -> noun)'),\n",
       " ('стеклографироваться',\n",
       "  'verb',\n",
       "  'стеклографированный',\n",
       "  'adj',\n",
       "  'rule664(verb + енн(ый) -> adj)'),\n",
       " ('разъясняться',\n",
       "  'verb',\n",
       "  'разъяснение',\n",
       "  'noun',\n",
       "  'rule256(verb + ниj(е) -> noun)'),\n",
       " ('разъясняться',\n",
       "  'verb',\n",
       "  'разъяснительный',\n",
       "  'adj',\n",
       "  'rule652(verb + тельн(ый)/ительн(ый) -> adj)'),\n",
       " ('разъясняться',\n",
       "  'verb',\n",
       "  'разъясниваться',\n",
       "  'verb',\n",
       "  'rule842(verb + ива(ть)/ва(ть)/а3(ть) -> verb)'),\n",
       " ('хороводить', 'verb', 'хоровод', 'noun', 'rule446(verb + 0m2 -> noun)'),\n",
       " ('хороводить', 'verb', 'хороводный', 'adj', 'rule646(verb + н1(ый) -> adj)'),\n",
       " ('хороводить', 'verb', 'захороводить', 'verb', 'rule861(за + verb -> verb)'),\n",
       " ('хороводить', 'verb', 'хороводиться', 'verb', 'rule930(verb + ся -> verb)'),\n",
       " ('дарма', 'adv', 'задарма', 'adv', 'rule993(за + adv -> adv)'),\n",
       " ('втихомолку', 'adv', 'втихомолочку', 'adv', 'rule991(adv + ком -> adv)'),\n",
       " ('легонечко', 'adv', 'полегонечку', 'adv', 'rule1022(по + adv + у -> adv)')]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NOTE: закомментировать!\n",
    "all_connections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Построить граф и найти корни"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0df6e9d833e49c7903d86c7db55c4e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "derived_from = defaultdict(list)\n",
    "\n",
    "for word_b, pos_b, word_a, pos_a, rule_id in tqdm(all_connections):\n",
    "    if (word_a, pos_a) == (word_b, pos_b):\n",
    "        continue\n",
    "    derived_from[(word_a, pos_a)].append((word_b, pos_b, rule_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(derived_from)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "roots = []\n",
    "\n",
    "for pos_a in pos_all:\n",
    "    for word_a in words_by_pos[pos_a]:\n",
    "        if not derived_from[(word_a, pos_a)]:\n",
    "            roots.append((word_a, pos_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18951"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(roots)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Сохранить всё, что извлеклось"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE: todo!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
